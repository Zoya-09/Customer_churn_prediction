# -*- coding: utf-8 -*-
"""CustomerChurn_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dPahakgp-UytgxBQ35sTa53HO8UNitAU
"""

#importing necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go

#mounting google drive
from google.colab import drive
drive.mount('/content/drive')

#uploading training and testing datasets
data1 = pd.read_csv('/content/drive/MyDrive/customer_churn_dataset-testing-master.csv')
data2 = pd.read_csv('/content/drive/MyDrive/customer_churn_dataset-training-master.csv')

#dataset1 information
data1.info()

#dataset2 information
data2.info()

#merging both dataset
df = pd.concat([data1, data2])

#printing first few rows of the dataset
df.head()

#dataset innformation
df.info()

#checking null values
df.isnull().sum()

# handling null values by drop method
df = df.dropna()

#rechecking null values
df.isnull().sum()

#checking duplicate values
df.duplicated().sum()

#dataset description
df.describe()

#dropping CustomerID column from the dataset
df = df.drop(columns=['CustomerID'])

df

#dataset head rows
df.head()

# printing customer churn distributiion pie chart
fig = px.pie(df, names="Churn", hole=0.5,
             title="Customer Churn Distribution",
             color="Churn",
             color_discrete_map={0.0: "green", 1.0: "red"})  # 0 = Not Churned, 1 = Churned
fig.show()

# creating histogram for churn by age distribution
fig = px.histogram(df, x="Age", color="Churn", marginal="box", nbins=40,
title="Age Distribution by Churn", barmode="overlay")
fig.show()

# printing histogram for the churn ditribution by users gender
fig = px.histogram(df, x="Gender", color="Churn", barmode="group",
                   title="Churn distribution by gender")
fig.show()

# printing churn distribution by tenure
fig = px.box(df, x="Churn", y="Tenure", title="Tenure vs Churn")
fig.show()

# creating violin plot for churn distribution by usage frequency
fig = px.violin(df, x="Churn", y="Usage Frequency", color="Churn", box=True,
                title=" Churn Distribution by Usage Frequency")
fig.show()

# BAr plot for churn distribution by subscription types
fig = px.histogram(df, x="Subscription Type", color="Churn", barmode="group",
                   title="Churn by Subscription Type")
fig.show()

# box plot for churn distribution by total spend
fig = px.box(df, x="Churn", y="Total Spend", color="Churn",
             title="Churn by Total Spend Distribution")
fig.show()

# box plot for churn by payment delay
fig = px.box(df, x="Churn", y="Payment Delay", color="Churn",
             title="Payment Delay Distribution by Churn")
fig.show()

#churn distribution by support calls
fig = px.box(df, x="Churn", y="Support Calls", title="Support Calls vs Churn")
fig.show()

# creating correlation heatmap for numerical features
corr = df.corr(numeric_only=True)
fig = px.imshow(corr, text_auto=True, color_continuous_scale="RdBu_r",
                title="Correlation Heatmap of Numeric Features")
fig.show()

# importing train-test split and evaluation metrics
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# improting mmodels
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

#copying dataset
df_model = df.copy()

# Replacing 'Female' with 0 and 'Male' with 1 in the 'Gender' column
df_model['Gender'] = df_model['Gender'].replace({'Female': 0, 'Male': 1})

# One-Hot Encoding for Subscription Type and Contract Length
df_model = pd.get_dummies(df_model, columns=['Subscription Type', 'Contract Length'], dtype=int)

df_model.head()

df_model.columns

# Features (X) and Target (y)
X = df_model.drop(columns=['Churn'])
y = df_model['Churn']

# splitting data into Train-Test (80-20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Train shape:", X_train.shape)
print("Test shape:", X_test.shape)

#feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initializing models
log_reg = LogisticRegression(max_iter=500, random_state=42)
rf = RandomForestClassifier(n_estimators=200, random_state=42)
xgb = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42, use_label_encoder=False, eval_metric='logloss')

# Logistic Regression training (scaled data)
log_reg.fit(X_train_scaled, y_train)

#Training random forest model
rf.fit(X_train, y_train)

#training xgboost model
xgb.fit(X_train, y_train)

# Making Predictions
y_pred_log = log_reg.predict(X_test_scaled)
y_pred_rf = rf.predict(X_test)
y_pred_xgb = xgb.predict(X_test)

#printing accuracy score for logistic regression model
print("Logistic Regression")
print("Accuracy:", accuracy_score(y_test, y_pred_log))

# printing classification report for logistic regression
print("Logistic Regression")
print(classification_report(y_test, y_pred_log))

# printing Confusion Matrix for Logistic Regression
cm_log = confusion_matrix(y_test, y_pred_log)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_log, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Logistic Regression')
plt.show()

#printing accuracy score for random forest model
print("Random Forest")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))

# printing classification report for random forest model
print("Random Forest")
print(classification_report(y_test, y_pred_rf))

# Printing Confusion Matrix for Random Forest
cm_rf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Random Forest')
plt.show()

#printing accuracy score for xgboost model
print("XGBoost")
print("Accuracy:", accuracy_score(y_test, y_pred_xgb))

# printing classification report for xgboost
print("XGBoost")
print(classification_report(y_test, y_pred_xgb))

# printing Confusion Matrix for XGBoost
cm_xgb = confusion_matrix(y_test, y_pred_xgb)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - XGBoost')
plt.show()